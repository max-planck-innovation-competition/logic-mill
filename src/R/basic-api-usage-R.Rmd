---
title: "Logic Mill API"
author: "Erik Buunk"
date: "2025-04-15"
output:
  html_document:
    df_print: paged
  pdf_document: default
---
# Release

Updated for use with Open Alex and DocDB families and new models (Pat-SPECTER and PaECTER)

# Preparation

Add your API KEY in the `.env` file

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
readRenviron(".env")
API_KEY <- paste('Bearer', Sys.getenv("API_KEY"))
```

# Basic Logic Mill API Usage

Based on: <https://www.dataquest.io/blog/r-api-tutorial/>

Documentation for the Logic Mill API: <https://api.logic-mill.net/api/v1/graph>

```{r message=FALSE, include=FALSE}
# install.packages(c("httr", "jsonlite", "ghql", "dplyr"))
```

```{r echo=TRUE, message=FALSE}
library(httr)
library(jsonlite)
library(ghql)
library(dplyr)
URL = 'https://api.logic-mill.net/api/v1/graphql/'

# Set up headers with API key from environment
headers = list(
  'content-type' = 'application/json',
  'Authorization' = API_KEY
)

# Define the default model to use
DEFAULT_MODEL = "patspecter"
```

## Get the version

This simple request will get the current version of the API and is also an easy way to check if the server is running and the requests are constructed the correct way.

```{r}
# use single quotes
query <- '{
  Version
}'
body = list(query = query)

res = POST(URL, query = body, headers=headers)

print(res)
```

```{r}
# Get data and some error handling
if (res$status_code == 200) {
    data = fromJSON(rawToChar(res$content))$data
    print(data$Version)
} else {
    print("An error has occured")
}

```

## Get the names of document sets (indices)

<https://api.logic-mill.net/api/v1/graph/?query=%7B%0A%20%20IndicesNames%20%7B%0A%20%20%20%20amountOfDocuments%0A%20%20%20%20name%0A%20%20%7D%0A%7D>

```{r}
query = '{
  IndicesNames {
    amountOfDocuments
    name
  }
}'
body = list(query = query)
res = POST(URL, query = body, headers=headers)
data = fromJSON(rawToChar(res$content))$data

```

The list of all the available indices

```{r}
indices <- data$IndicesNames$name
indices
```

## Getting basic document information

By supplying an IDs

```{r}
variables <-  fromJSON('{
  "data": [
    {
      "index": "publications",
      "id": "W2531700612"
    },
    {
      "index": "patents",
      "id": "64440517"
    },
    {
      "index": "patents",
      "id": "US11394112B2"
    }
  ]
}')


conn <- GraphqlClient$new(
  url = URL,
  headers = list(Authorization = API_KEY)
)

query = 'query Documents($data: [DatabaseSearchDocument]) {
  Documents(data: $data) {
    id
    url
    title
    type
    index
    doi
    pubmed
    publicationDate
    familyEarliestFilingDate
    familyEarliestPriorityDate
    applnID
    applnAuth
    publNo
    familyCPCClasses
    isParatext
    isRetracted
    PaecterEmbedding
    PatspecterEmbedding
    Specter2Embedding
  }
}
'

new <- Query$new()$query('link', query)

res = conn$exec(new$link, variables = variables) %>%
    fromJSON(flatten = F)

res$data$Documents  %>% as_tibble()


```


## Get the numerical representation/embedding of document in database

The query is the same as above, only different fields are requested

```{r}

# create new query
query <-  'query Documents($data: [DatabaseSearchDocument]) {
  Documents(data: $data) {
    id
    PatspecterEmbedding
  }
}
'

new <- Query$new()$query('link', query)

variables <-  fromJSON('{
  "data": [
    {
      "index": "publications",
      "id": "W2531700612"
    }
  ]
}')

res = conn$exec(new$link, variables = variables) %>%
    fromJSON(flatten = F)

res$data$Documents$PatspecterEmbedding[[1]][1:20]

```

## Search *n* most similar documents compared to a document in the database

```{r}

variables <-  fromJSON('{
  "model": "patspecter",
  "amount": 25,
  "id": "91081326",
  "index": "patents",
  "indices": [
    "patents",
    "publications"
  ]
}')


conn <- GraphqlClient$new(
  url = URL,
  headers = list(Authorization = API_KEY)
)
query = 'query SimilaritySearch($index: String!, $id: String!, $amount: Int, $indices: [String], $model: String!) {
  SimilaritySearch(
    index: $index
    id: $id
    amount: $amount
    indices: $indices
    model: $model
  ) {
    id
    score
    index
    document {
      title
      url
    }
  }
}
'


new <- Query$new()$query('link', query)

res = conn$exec(new$link, variables = variables) %>% fromJSON(flatten=T)

res$data$SimilaritySearch


```


## Create a new embedding for a user document

We use the `embedDocument` endpoint. This query expects an `LmDocumentMutationObject`. This object look like this

    id: String!
    parts: [LmDocumentPartsMutationObject]

`LmDocumentPartsMutationObject` is a key/value pair for every field (title and abstract)

The `id` is for identification purposes and can be any number.

Many time we may have the data available in some datastructure (CSV, Excel file, dictionary). In the following example we will use a dictionary.

```{r}
# our data
id <- c("ML001", "ML002", "ML003")
title <- c('Towards A Rigorous Science of Interpretable Machine Learning',
           'Machine Learning Interpretability: A Science rather than a tool',
           'Opening the black box of neural networks: methods for interpreting neural network models in clinical applications'
           )

# Note: Abstracts where truncated for brevity
abstract <- c("As machine learning systems become ubiquitous, there has been a surge of interest in interpretable machine learning: systems that provide explanation for their outputs. These explanations are often used to qualitatively assess other criteria such as safety or non-discrimination. However, despite the interest in interpretability, there is very little consensus on what interpretable machine learning is and how it should be measured. In this position paper, we first define interpretability and describe when interpretability is needed (and when it is not). Next, we suggest a taxonomy for rigorous evaluation and expose open questions towards a more rigorous science of interpretable machine learning.",
              "The term interpretability is oftenly used by machine learning researchers each with their own intuitive understanding of it. There is no universal well agreed upon definition of interpretability in machine learning. As any type of science discipline is mainly driven by the set of formulated questions rather than by different tools in that discipline, e.g. astrophysics is the discipline that learns the composition of stars, not as the discipline that use the spectroscopes. Similarly, we propose that machine learning interpretability should be a discipline that answers specific questions related to interpretability. These questions can be of statistical, causal and counterfactual nature.",
              'Artificial neural networks (ANNs) are powerful tools for data analysis and are particularly suitable for modeling relationships between variables for best prediction of an outcome. While these models can be used to answer many important research questions, their utility has been critically limited because the interpretation of the \"black box\" model is difficult. Clinical investigators usually employ ANN models to predict the clinical outcomes or to make a diagnosis; the model however is difficult to interpret for clinicians. To address this important shortcoming of neural network modeling methods, we describe several methods to help subject-matter audiences (e.g., clinicians, medical policy makers) understand neural network models.')

biblios = data.frame(id, title, abstract)
biblios
```


```{r}
# first item
biblio = biblios[1,]

data = list(id=biblio$id)

parts = list()
# prepare the data
for (col in colnames(biblio)){
    if (col!= 'id') {
        record = data.frame(key=col, value=biblio[,c(col)])
        parts = rbind(parts, record)
    }

}

data$parts <-  parts

variables <-  list(data=data, model=DEFAULT_MODEL)
variables
```

```{r}

query = 'query encodeDocument($data: EncodeObject, $model: String!) {
  encodeDocument(data: $data, model: $model)
}'

new <- Query$new()$query('link', query)

res = conn$exec(new$link, variables = variables) %>%
    fromJSON(flatten = F)

res$data$encodeDocument %>% as_tibble()
```

```{r}
URL <- 'https://api.logic-mill.net/api/v1/graphql/'
variables <-  fromJSON('{"data":{"id":"ID","parts":[{"key":"title","value":"Airbags"},{"key":"abstract","value":"Airbags are one of the most important safety gears in motor vehicles such as cars and SUVs. These are cushions built into a vehicle that are intended to inflate in case of a car accident in order to protect occupants from injuries by preventing them from striking the interior of vehicle during a crash."}]}, "model": "patspecter"}')



query = 'query encodeDocument($data: EncodeObject, $model: String!) {
  encodeDocument(data: $data, model: $model)
}'

new <- Query$new()$query('link', query)

res = conn$exec(new$link, variables = variables) %>%
    fromJSON(flatten = F)

res$data$encodeDocument %>% as_tibble()
```

## Create embeddings for multiple documents

```{r}
query = 'query encodeDocuments($data: [EncodeObject], $model: String!) {
  encodeDocuments(data: $data, model: $model) {
    id
    embedding
  }
}'
new <- Query$new()$query('link', query)

df <- data.frame()

for (i in 1:length(biblios)){
    biblio <-  biblios[i,] # third record
    variables <-  list(data=list(id=biblio$id), model=DEFAULT_MODEL)
    parts <-  list()
    for (col in colnames(biblio)){
        if (col!= 'id') {
            record <-  data.frame(key=col, value=biblio[,c(col)])
            parts <-  rbind(parts, record)
        }

    }

    variables$data$parts <-  parts

    res <-  conn$exec(new$link, variables = variables) %>%
         fromJSON(flatten = F)

    # combine the data into a single dataframe
    # Extract both id and embedding from the response
    row <- tibble(
        id = res$data$encodeDocuments$id,
        embedding = res$data$encodeDocuments$embedding
    )
    df <- rbind(df, row)

}

df
```

## Find similarity between user supplied documents

```{r}
query <- 'query encodeDocumentAndSimilarityCalculation($data: [EncodeObject], $similarityMetric: similarityMetric, $model: String!) {
  encodeDocumentAndSimilarityCalculation(
    data: $data,
    similarityMetric: $similarityMetric,
    model: $model
  ) {
    similarities
    xs {
      id
    }
    ys {
      id
    }
  }
}'
new <- Query$new()$query('link', query)

```

```{r}

variables = NULL
data = NULL
for( i in 1:nrow(biblios)) {
    biblio = biblios[i,]

    biblio
    record = NULL
    key_values = NULL
    for (k in colnames(biblio)){
        if (k!="id") {
            v = biblio[[k]]
            key_values = rbind(key_values, data.frame(key=k, value = v))
        }
    }

    record = list(id=biblio$id)
    record[["parts"]]= key_values

    data = rbind(data, record)
}

rownames(data)=1:nrow(data)
variables = list(data=data.frame(data), similarityMetric='cosine', model=DEFAULT_MODEL)

```

```{r}
res <-  conn$exec(new$link, variables = variables) %>%
     fromJSON(flatten = F)

df = data.frame(res$data$encodeDocumentAndSimilarityCalculation$similarities)

colnames(df) <- t(res$data$encodeDocumentAndSimilarityCalculation$xs)
rownames(df) <- t(res$data$encodeDocumentAndSimilarityCalculation$ys)
df

```

## Find n similar documents

```{r}
variables <-  fromJSON('{
  "model": "patspecter",
  "data": [
    {
      "key": "title",
      "value": "Airbags"
    },
    {
      "key": "abstract",
      "value": "Airbags are one of the most important safety gears in motor vehicles such as cars and SUVs. These are cushions built into a vehicle that are intended to inflate in case of a car accident in order to protect occupants from injuries by preventing them from striking the interior of vehicle during a crash."
    }
  ],
  "amount": 25,
  "indices": [
    "patents",
    "publications"
  ]
}')


conn <- GraphqlClient$new(
  url = URL,
  headers = list(Authorization = API_KEY)
)
query = 'query embedDocumentAndSimilaritySearch($data: [EncodeDocumentPart], $indices: [String], $amount: Int, $model: String!) {
  encodeDocumentAndSimilaritySearch(
    data: $data
    indices: $indices
    amount: $amount
    model: $model
  ) {
    id
    score
    index
    document {
      title
      url
    }
  }
}
'

new <- Query$new()$query('link', query)

res = conn$exec(new$link, variables = variables) %>%
    fromJSON(flatten = T
             )

res$data$encodeDocumentAndSimilaritySearch %>% as_tibble()

```

